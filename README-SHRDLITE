Files:

Graph.ts: 
An implementation of the A* search algorithm, under the name aStarOriginal (which is not used by default). Also an implementation of Anytime Repairing A*, which is the algorithm used by default. See more under extensions. 

Interpreter.ts: 
An interpreter which recursively goes through the parse and returns all interpretations which match the given parse result. Relations and constraints for each object/relation are also defined here and used in the recursive definition.

Planner.ts: 
Contains heuristics, goal and neighbour functions used by the A* search algorithm. The state and state graph are also defined here. Returns a plan which is derived from an interpretation.


Extensions:

Additional relations: 
"between" can be used for example in the small world by typing "put the white ball between the blue table and the blue box". Additional constraints and relation checks are implemented that can support three objects. There is the possibility to add more relations which involve two or three objects. The relations and constraints are defined in a new seperate functions with the name "triple" in them. These functions are almost identical to the ones used for the relations involving just two objects.

User questions: 
Added two user questions. One of them allows the user to ask where an object is located in the world. The other results in a simple yes or no answer, depending on if an object matching a description exists in the world. "where is a blue ball?" returns the location of a blue ball. Existance question "is there a blue ball?" returns yes if a blue ball exists in the world. These sentence structures are located in the grammar, the interpreter finds the objects, or doesn't, and the result is shown as an alert (followed by an interpretation error).

Clarification questions:
The clarification questions work by showing a list of all possible interpretations, letting the users choose which one to carry out. First, if there are several parses, a clarification question is asked to determine which one to interpret, eg. if the user meant "the ball that is in a box" or just "the ball", when asking "put the ball in a box on the floor". Secondly, during the interpretation, if there are several objects which may fulfill the selected parse, a question is asked to determine which of the objects in the world the user meant. The implementation uses standard Javascript prompts to ask the clarification questions.

Alternative search algorithms:
Our implementation currently uses Anytime Repairing A* search, as defined in this paper: http://papers.nips.cc/paper/2382-ara-anytime-a-with-provable-bounds-on-sub-optimality.pdf. It works by finding paths to the goal state starting with a multiple of the heuristic factor, and gradually reducing the factor until either an optimal solution is found or timeout occurs. This makes it possible to find solutions in very complicated environments in the time allowed, but the solution might not be optimal if finding it takes too long.

Using an inflated heuristic removes the optimality guarantee, but increases search speed, which is the reason why it is called an anytime algorithm. If the algorithm would simply use A* search iteratively with decreasing factor, a lot of redundant work would be performed. In order to avoid this, the algorithm keeps track of which nodes have been visited, which nodes have been closed (that is have been the lowest valued nodes in the queue as in regular A*), and which nodes have had a new path found after they are closed (called inconsistent nodes). After each pass through the search function, the algorithm calculates how optimal the solution is, and if it is optimal no further search is made. If it is not optimal, which can occur if there are nodes with a lower combination of cost and heuristic values to the goal remaining after a search pass, the open and inconsitent nodes are placed in the queue again with a lower factor to the heuristic function. Only these nodes are reevaluated by the search function, and any nodes that are visited are either placed in the open or inconsistent sets depending on whether they were previously closed. This continues until an optimal path is found, or time runs out, in which case the best path found so far is returned. 

The algorithm is implemented using hash tables where possible, which makes it pretty efficient even with the extra overhead. This is done by using a string representation of the state, i.e. a string combination of the stacks, arm position, holding and action. This combination of strings uniquely represents each possible state, independently of how the path to it looks. This makes it possible to match each unique state to a specially constructed path node, that contains its parent, using a hash set. Each visited node also has a known path to it, and the path node that contains the parent node of the currently best path to the node in question is stored as the value in the set of visited nodes, with the string representation of the state being the key. This allows O(1) lookup both to find if a state has been visited/closed/is inconsistend, and to find the best path to a given state.

Note however that the extra overhead of using extra sets, and iterating to find an optimal solution, makes the algorithm time out sometimes using aStarTests. Test number one times out sometimes after 16 ms, and after three iterations, which neatly demonstrates how the algorithm fails gracefully by returning a sub-optimal path instead of returning nothing at all. The console prints that a sub-optimal solution was found, as well as the best possible optimal solution based on the current bound (see the paper for information on how that is calculated). 

An example of how well the algorihm works can be found by comparing our implementation to the demo implementation on the course homepage. Using the medium world, the utterance "put the yellow box on the green brick" results in a timeout. Using our algorithm finds the optimal solution (after four iterations, which means it actually found four different solutions.) in less than a second or so. The console prints the costs of all found paths, and can sometimes reveal interesting information, like how many iterations with the same cost some paths requires before finally managing to improve the final path cost by several points.

The choice of the initial value of epsilon can have a big impact on how quickly the algorithm runs, and moreover it is problem-dependent. In the test cases, an initial value for epsilon of around 1.1 is super quick, probably because it never overestimates the cost, but instead results in a more accurate heuristic. This means that it never has to try to improve the solution. But this is a very simple problem, where regular A* can also be made a bit faster by multiplying with 1.1. In the real shrdlite world a higher initial value such as 3 or 4 is often beneficial after empirical testing. However, this is something that could be explored much further.